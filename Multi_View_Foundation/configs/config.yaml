# Multi-View Foundation configuration (scaffold)
#
# Step-to-args map (F0-F7):
# F0 paired dataset build:
#   paths.data_dir, paths.polymer_file, paths.polymer_file_d2, paths.paired_index
#   data.random_seed, data.max_samples_d1, data.max_samples_d2
#   alignment_views, views.*
# F1 alignment embeddings / alignment training:
#   alignment_views, views.*, *_encoder.*
#   model.*, training.*, alignment_training.*, alignment_e2e.*
#   pipeline.step1_alignment_mode
# F2 retrieval evaluation:
#   evaluation.*, pipeline.step2_use_alignment
# F3 property heads:
#   property.*, pipeline.step3_use_alignment
# F4 OOD analysis:
#   ood.*, pipeline.step4_use_alignment
# F5 foundation inverse (resample):
#   foundation_inverse.*, pipeline.step5_use_alignment
# F6 OOD-aware inverse objective:
#   ood_aware_inverse.*
# F7 chemistry/physics analysis:
#   chem_physics_analysis.*
# F8 paper package export:
#   paper_results.*

# F0 shared paths/data for paired dataset construction
paths:
  data_dir: "../Data"
  polymer_file: "../Data/Polymer/SMiPoly_polymers.gz"
  polymer_file_d2: "../Data/Polymer/PolyInfo_Homopolymer.csv"
  property_dir: "../Data/Property"
  results_dir: "results"
  paired_index: "results/paired_index.csv"

data:
  random_seed: 42
  max_samples_d1: 1000000
  max_samples_d2: 12888

# F0/F1 view selection
alignment_views: ["smiles", "smiles_bpe", "selfies", "group_selfies", "graph"]

views:
  smiles_bpe:
    enabled: true
  selfies:
    enabled: true
  group_selfies:
    enabled: true
    tokenizer_path: "../Bi_Diffusion_Group_SELFIES/results/tokenizer.pkl"
  graph:
    enabled: true

# F1 alignment model + optimization args
model:
  projection_dim: 384  # default for small; run_pipeline.sh aligns with 9-method backbone sizes: 384/640/960/1280
  projection_hidden_dims: [768]  # default for small; presets: [768],[1280],[1920],[2560]
  view_dropout: 0.3
  temperature: 0.07

training:
  batch_size: 512
  learning_rate: 1.0e-4
  max_steps: 200000
  warmup_steps: 2000

alignment_training:
  batch_size: 256
  learning_rate: 1.0e-3
  weight_decay: 0.0
  max_epochs: 10
  val_ratio: 0.1
  log_every: 50
  datasets: ["d1", "d2"]

alignment_e2e:
  batch_size: 64
  learning_rate: 1.0e-5
  weight_decay: 0.01
  max_epochs: 3
  val_ratio: 0.05
  log_every: 50
  datasets: ["d1", "d2"]
  max_samples: null

# F1/F2/F3/F4/F5 pipeline toggles
pipeline:
  step1_alignment_mode: "frozen"  # none|frozen|e2e|both
  step2_use_alignment: true
  step3_use_alignment: true
  step4_use_alignment: true
  step5_use_alignment: true

# F1 embedding-figure args
alignment_embeddings:
  generate_figures: true

# F2 retrieval args
evaluation:
  recall_ks: [1, 5, 10]
  max_samples_per_dataset: 5000
  generate_figures: true

# F4 OOD args
ood:
  nn_k: 50
  use_faiss: true
  generate_figures: true

# F3 property-head args
property:
  files: ["Td.csv"]
  max_samples: null
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  model_type: "mlp"
  views: null
  use_alignment: true
  generate_figures: true
  hyperparameter_tuning:
    n_trials: 150
    enabled: true
    tuning_epochs: 50
    tuning_patience: 10
    final_training_epochs: 500
    metric: "r2"
    search_space:
      num_layers: [3, 4, 5]
      neurons: [64, 128, 256, 512, 1024]
      learning_rate: [4.0e-4, 6.0e-4, 8.0e-4, 1.0e-3]
      dropout: [0.1, 0.2, 0.3]
      batch_size: [8, 16, 32, 64, 128]

# F5 foundation inverse args
foundation_inverse:
  enabled: true
  run_all_properties: false       # single-property test default
  property: "Td"  # Tg, Tm, Td, Eg
  target: 300.0
  target_mode: "ge"  # window: |pred-target|<=epsilon, ge: pred>=target, le: pred<=target
  epsilon: 20.0
  # Optional per-property overrides used when run_all_properties=true.
  targets: {}
  target_modes: {}
  epsilons: {}
  sampling_target: 100              # accepted hit target for resampling
  sampling_num_per_batch: 512       # candidates generated each outer batch
  sampling_batch_size: 128          # model decode batch size inside sampler
  sampling_max_batches: 200         # hard stop to avoid infinite loops
  proposal_views: ["selfies", "smiles"]       # all|csv/list, proposal generation views used in round-robin
  sampling_temperature: null        # null => use method sampling.temperature
  sampling_num_atoms: null          # graph-only optional override
  # Optional comma-separated class filter. Supported classes:
  # polyimide, polyester, polyamide, polyurethane, polyether,
  # polysiloxane, polycarbonate, polysulfone, polyacrylate, polystyrene
  target_class: "polyamide"         # empty string disables class filter
  require_validity: true
  require_two_stars: true
  require_novel: true
  require_unique: true
  max_sa: 4.5
  per_view_min_hits: 2
  per_view_quota_relax_after_batches: 12
  committee_properties: ["Td"]  # explicit committee export list for F5/F6/F7 workflow
  property_model_mode: "all"          # single|all; all = aggregate all available F3 models for this property
  property_model_path: ""
  rerank_strategy: "d2_distance"
  rerank_top_k: 100
  generate_figures: true
  ood_k: 5
  encoder_view: "selfies"  # F5 scoring backbone + fallback proposal view
  use_alignment: true
  alignment_checkpoint: ""

# F6 OOD-aware inverse args
ood_aware_inverse:
  enabled: true
  run_all_properties: false       # single-property test default
  encoder_view: ""              # fallback anchor view for metadata/model_size if needed
  ood_views: "all"              # all|csv list; multi-view OOD distance aggregation uses mean over available views
  property: "Td"                # fallback: foundation_inverse.property
  target: null                  # fallback: foundation_inverse.target
  target_mode: ""               # fallback: foundation_inverse.target_mode (window/ge/le)
  epsilon: null                 # fallback: foundation_inverse.epsilon
  # Optional per-property overrides used when run_all_properties=true.
  targets: {}
  target_modes: {}
  epsilons: {}
  top_k: 100
  property_weight: 0.6
  ood_weight: 0.2
  uncertainty_weight: 0.15      # penalize committee disagreement (prediction std)
  constraint_weight: 0.05       # soft constraints on non-target properties
  sa_weight: 0.0                # optional SA penalty term
  descriptor_weight: 0.25       # optional structure-prior penalty (ring/aromatic for Td-like tasks)
  constraint_properties: []     # empty => auto from available pred_<PROP>_mean + targets map
  descriptor_constraints:
    aromatic_ring_count:
      target: 1.0
      mode: ge
      weight: 1.0
      min: 2
    ring_count:
      target: 1.0
      mode: ge
      weight: 1.0
      min: 3
  constraint_weights: {}        # optional per-property multipliers, e.g. {Tm: 2.0}
  normalization: "minmax"       # minmax|rank|none
  ood_k: 5
  compute_d2_distance_if_missing: true
  use_alignment: true
  alignment_checkpoint: ""
  generate_figures: true

# F7 chemistry/physics analysis args
chem_physics_analysis:
  enabled: true
  properties: ["Td"]
  # Optional path templates with {property}, e.g.:
  # "results/step5_foundation_inverse/files/candidate_scores_{property}.csv"
  candidate_scores_template: ""
  topk_scores_template: ""
  max_reference_samples: null
  top_k: 100
  generate_figures: true
  # Optional per-property target config for physics panels.
  # If omitted, Step7 uses property_hit/abs_error from input files when available.
  targets: {}
  target_modes: {}
  epsilons: {}

# F8 paper package export args (collect F1-F7 into paper-ready structure)
paper_results:
  enabled: true
  output_dir: "paper_package"    # relative path resolves under results_dir
  include_large_csv: true        # include candidate_scores / full OOD score tables
  include_figures: true

# F1 backbone encoder args (used by F1/F5/F6)
smiles_encoder:
  method_dir: "../Bi_Diffusion_SMILES"
  config_path: "../Bi_Diffusion_SMILES/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 256
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

smiles_bpe_encoder:
  method_dir: "../Bi_Diffusion_SMILES_BPE"
  config_path: "../Bi_Diffusion_SMILES_BPE/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 256
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

selfies_encoder:
  method_dir: "../Bi_Diffusion_SELFIES"
  config_path: "../Bi_Diffusion_SELFIES/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 256
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

group_selfies_encoder:
  method_dir: "../Bi_Diffusion_Group_SELFIES"
  config_path: "../Bi_Diffusion_Group_SELFIES/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 128
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

graph_encoder:
  method_dir: "../Bi_Diffusion_graph"
  config_path: "../Bi_Diffusion_graph/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "graph_backbone_best.pt"
  tokenizer_path: ""
  graph_config_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 64
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null
