# Multi-View Foundation configuration (scaffold)
#
# Step-to-args map (F0-F7):
# F0 paired dataset build:
#   paths.data_dir, paths.polymer_file, paths.polymer_file_d2, paths.paired_index
#   data.random_seed, data.max_samples_d1, data.max_samples_d2
#   alignment_views, views.*
# F1 embedding extraction:
#   alignment_views, views.*, *_encoder.*
# F2 retrieval evaluation:
#   evaluation.*
# F3 property heads:
#   property.*
# F4 OOD analysis:
#   ood.*
# F5 foundation inverse (resample):
#   foundation_inverse.*
# F6 OOD-aware inverse objective:
#   ood_aware_inverse.*
# F7 chemistry/physics analysis:
#   chem_physics_analysis.*
# F8 paper package export:
#   paper_results.*

# F0 shared paths/data for paired dataset construction
paths:
  data_dir: "../Data"
  polymer_file: "../Data/Polymer/SMiPoly_polymers.gz"
  polymer_file_d2: "../Data/Polymer/PolyInfo_Homopolymer.csv"
  property_dir: "../Data/Property"
  results_dir: "results"
  paired_index: "results/paired_index.csv"

data:
  random_seed: 42
  max_samples_d1: 1000000
  max_samples_d2: 12888

# F0/F1 view selection
alignment_views: ["smiles", "smiles_bpe", "selfies", "group_selfies", "graph"]

views:
  smiles_bpe:
    enabled: true
  selfies:
    enabled: true
  group_selfies:
    enabled: true
    tokenizer_path: "../Bi_Diffusion_Group_SELFIES/results/tokenizer.pkl"
  graph:
    enabled: true

# F1 embedding-figure args
alignment_embeddings:
  generate_figures: true

# F2 retrieval args
evaluation:
  recall_ks: [1, 5, 10]
  max_samples_per_dataset: 5000
  generate_figures: true

# F4 OOD args
ood:
  nn_k: 50
  use_faiss: true
  generate_figures: true
  distance_metric: "cosine"

# F3 property-head args
property:
  files: ["Tg.csv", "Tm.csv", "Td.csv", "Eg.csv"]
  max_samples: null
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  model_type: "mlp"
  views: null
  generate_figures: true
  hyperparameter_tuning:
    n_trials: 150
    enabled: true
    tuning_epochs: 50
    tuning_patience: 10
    final_training_epochs: 500
    metric: "r2"
    search_space:
      num_layers: [2, 3, 4, 5]
      neurons: [64, 128, 256, 512, 1024]
      learning_rate: [4.0e-4, 6.0e-4, 8.0e-4, 1.0e-3]
      dropout: [0.1, 0.2, 0.3]
      batch_size: [4, 8, 16, 32, 64, 128]

# F5 foundation inverse args
foundation_inverse:
  enabled: true
  run_all_properties: true
  property: "Tg, Tm, Td, Eg"
  targets:
    Tg: 300.0
    Tm: 300.0
    Td: 450.0
    Eg: 6.0
  target_mode: "ge"  # window: |pred-target|<=epsilon, ge: pred>=target, le: pred<=target
  epsilon: 20.0
  sampling_target: 100
  sampling_num_per_batch: 512
  sampling_batch_size: 128
  sampling_max_batches: 1000
  proposal_views: ["selfies"]   # which diffusion backbone(s) generate candidate molecules; list of views or "all"
  sampling_temperature: null
  sampling_num_atoms: null
  # Optional comma-separated class filter. Supported classes:
  # polyimide, polyester, polyamide, polyurethane, polyether,
  # polysiloxane, polycarbonate, polysulfone, polyacrylate, polystyrene
  target_class: "polyamide"         # empty string disables class filter
  require_validity: true
  require_two_stars: true
  require_novel: true
  require_unique: true
  max_sa: 4.5
  per_view_min_hits: 2
  per_view_quota_relax_after_batches: 12
  property_model_mode: "single"     # single: use one MLP (encoder_view's); all: ensemble all view MLPs (committee)
  property_model_path: ""           # explicit MLP path; auto-resolved from step3 results if empty (single mode only)
  rerank_strategy: "ood_prop"
  rerank_top_k: 100
  generate_figures: true
  ood_k: 5
  # ood_prop = cosine dist to D2 (property MLP training set); ood_gen = cosine dist to D1 (backbone training set)
  encoder_view: "smiles"           # backbone used to embed candidates for property scoring and D2 OOD distance

# F6 OOD-aware inverse args
ood_aware_inverse:
  enabled: true
  run_all_properties: true
  encoder_view: ""              # backbone for D2 OOD distance; empty => inherits from foundation_inverse.encoder_view
  ood_views: "all"              # views used to compute per-view D2 distances, then averaged; "all" or comma-separated list
  property: "Tg, Tm, Td, Eg"
  target: null
  target_mode: ""
  epsilon: null
  top_k: 100
  property_weight: 0.6
  ood_weight: 0.2
  uncertainty_weight: 0.15      # penalize committee disagreement (prediction std)
  constraint_weight: 0.05       # soft constraints on non-target properties
  sa_weight: 0.0                # optional SA penalty term
  descriptor_weight: 0.25       # optional structure-prior penalty (ring/aromatic for Td-like tasks)
  constraint_properties: []     # empty => auto from available pred_<PROP>_mean + targets map
  descriptor_constraints:
    aromatic_ring_count:
      target: 1.0
      mode: ge
      weight: 1.0
      min: 2
    ring_count:
      target: 1.0
      mode: ge
      weight: 1.0
      min: 3
  constraint_weights: {}        # optional per-property multipliers, e.g. {Tm: 2.0}
  normalization: "minmax"       # minmax|rank|none
  ood_k: 5
  ood_gen_weight: 0.0  # informational only by default; set >0 to penalize generative OOD
  compute_d2_distance_if_missing: true
  generate_figures: true

# F7 chemistry/physics analysis args
chem_physics_analysis:
  enabled: true
  properties: ["Tg", "Tm", "Td", "Eg"]
  # Optional path templates with {property}, e.g.:
  # "results/step5_foundation_inverse/files/candidate_scores_{property}.csv"
  candidate_scores_template: ""
  topk_scores_template: ""
  max_reference_samples: null
  top_k: 100
  generate_figures: true
  # Optional per-property target config for physics panels.
  # If omitted, Step7 uses property_hit/abs_error from input files when available.
  targets: {}
  target_modes: {}
  epsilons: {}

# F8 paper package export args (collect F1-F7 into paper-ready structure)
paper_results:
  enabled: true
  output_dir: "paper_package"    # relative path resolves under results_dir
  include_large_csv: true        # include candidate_scores / full OOD score tables
  include_figures: true

# F1 backbone encoder args (used by F1/F5/F6)
smiles_encoder:
  method_dir: "../Bi_Diffusion_SMILES"
  config_path: "../Bi_Diffusion_SMILES/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 256
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

smiles_bpe_encoder:
  method_dir: "../Bi_Diffusion_SMILES_BPE"
  config_path: "../Bi_Diffusion_SMILES_BPE/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 256
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

selfies_encoder:
  method_dir: "../Bi_Diffusion_SELFIES"
  config_path: "../Bi_Diffusion_SELFIES/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 256
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

group_selfies_encoder:
  method_dir: "../Bi_Diffusion_Group_SELFIES"
  config_path: "../Bi_Diffusion_Group_SELFIES/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "backbone_best.pt"
  tokenizer_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 128
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null

graph_encoder:
  method_dir: "../Bi_Diffusion_graph"
  config_path: "../Bi_Diffusion_graph/configs/config.yaml"
  results_dir: ""
  model_size: "small"
  step_dir: "step1_backbone"
  checkpoint_name: "graph_backbone_best.pt"
  tokenizer_path: ""
  graph_config_path: ""
  checkpoint_path: ""
  pooling: "mean"
  timestep: 1
  batch_size: 64
  device: "auto"
  max_samples_d1: null
  max_samples_d2: null
